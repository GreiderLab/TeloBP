{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TeloNP Demo + Combining Reads with Alignment Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, '../TeloBP/')\n",
    "from TeloBP import *\n",
    "import constants as c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSampleKeyFromFilename(file):\n",
    "    NBtitle = [x for x in file.split('.') if \"NB\" in x][0]\n",
    "    NBtitle = [x for x in NBtitle.split('_') if \"NB\" in x][0]\n",
    "    NBtitle = NBtitle.replace(\"uq\", \"\")\n",
    "    Ftitle = [x for x in file.split('.') if \"F\" in x][0]\n",
    "    Ftitle = [x for x in Ftitle.split('_') if \"F\" in x][0]\n",
    "    sampleKey = Ftitle + \"_\" + NBtitle\n",
    "    return sampleKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we read in the tables which contain read qnames and alignment information\n",
    "\n",
    "sampleQnamesDir = \"../../Data/sampleQnamesData/assignment/\"\n",
    "\n",
    "sampleQnames = {}\n",
    "\n",
    "for root, dirs, files in os.walk(sampleQnamesDir):\n",
    "    for file in files:\n",
    "        if not file.endswith('.txt'):\n",
    "            continue\n",
    "        # skip empty files\n",
    "        if os.stat(os.path.join(root, file)).st_size == 0:\n",
    "            continue\n",
    "        print(file)\n",
    "        \n",
    "        sampleKey = getSampleKeyFromFilename(file)\n",
    "        print(sampleKey)\n",
    "        # read in table and set columns\n",
    "        sampleQnames[sampleKey] = pd.read_csv(os.path.join(root, file), delimiter='\\t', header=None)\n",
    "        sampleQnames[sampleKey].columns = [\"qname\", \"seqLength\", \"sampleQnamesChr\", \"subTeloAlignLength\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section will read in fastq files and extract the sequences for each read\n",
    "\n",
    "fastqReadDir = \"../../Data/Final.demultip.tagged.fastq\"\n",
    "\n",
    "for root, dirs, files in os.walk(fastqReadDir):\n",
    "    for filename in files:\n",
    "        print(filename)\n",
    "        if not filename.endswith(\".gz\") and not filename.endswith(\".fastq\") or \"AG\" in filename:\n",
    "            continue\n",
    "\n",
    "        sampleKey = getSampleKeyFromFilename(filename)\n",
    "        print(sampleKey)\n",
    "\n",
    "        if sampleKey not in sampleQnames.keys():\n",
    "            continue\n",
    "        print(f\"Processing {filename}\")\n",
    "        sampleDf = sampleQnames[sampleKey]\n",
    "\n",
    "        qnameTeloValues = []\n",
    "        file = os.path.join(root, filename)\n",
    "        print(file)\n",
    "        if filename.endswith(\"fastq.gz\"):\n",
    "            with gzip.open(file,\"rt\") as handle:\n",
    "                records = SeqIO.parse(handle,\"fastq\")\n",
    "                for record in records:\n",
    "                    if record.id not in sampleDf[\"qname\"].tolist():\n",
    "                        continue\n",
    "                    qnameTeloValues.append([record.id, record.seq])\n",
    "        elif filename.endswith(\"fastq\"):\n",
    "            for record in SeqIO.parse(file,\"fastq\"):\n",
    "                if record.id not in sampleDf[\"qname\"].tolist():\n",
    "                    continue\n",
    "                qnameTeloValues.append([record.id, record.seq])\n",
    "        qnameTeloValuesDf = pd.DataFrame(qnameTeloValues, columns = [\"qname\", \"seq\"])\n",
    "        sampleQnames[sampleKey] = pd.merge(sampleDf, qnameTeloValuesDf, on='qname', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each table in sampleQnames, remove rows with NaN in seq column\n",
    "# This is because some reads may not have been present in the fastq files\n",
    "popKeys = []\n",
    "sampleQnamesNan = {}\n",
    "for sampleKey in sampleQnames.keys():\n",
    "    # print(sampleKey)\n",
    "    sampleDf = sampleQnames[sampleKey]\n",
    "    if \"seq\" not in sampleDf.keys():\n",
    "        popKeys.append(sampleKey)\n",
    "        continue\n",
    "    # print(len(sampleDf))\n",
    "    for index, row in sampleDf.iterrows():\n",
    "        if row[\"seq\"] is np.nan:\n",
    "            if sampleKey not in sampleQnamesNan.keys():\n",
    "                sampleQnamesNan[sampleKey] = [row]\n",
    "            else:\n",
    "                sampleQnamesNan[sampleKey].append(row)\n",
    "            sampleDf.drop(index, inplace=True)\n",
    "\n",
    "print(popKeys)\n",
    "for key in popKeys:\n",
    "    sampleQnames.pop(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find any duplicated qnames in the tables:\n",
    "# No output from this cell is good. It means there are no duplicated qnames.\n",
    "for sampleKey in sampleQnames.keys():\n",
    "    sampleDf = sampleQnames[sampleKey]\n",
    "    # print out any duplicates in the qname column\n",
    "    dupQnames = sampleDf[sampleDf.duplicated(['qname'])][\"qname\"].tolist()\n",
    "    if len(dupQnames) > 0:\n",
    "        # sort by qname\n",
    "        print(sampleKey)\n",
    "        sortedDf = sampleDf.sort_values(by=['qname'])\n",
    "        print(sortedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run TeloBP on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel\n",
    "\n",
    "outputDir = \"output/TeloNPInprogress\"\n",
    "\n",
    "def rowToTeloBP(row):\n",
    "    # This if statement is to catch any rows which have NaN in the seq column. \n",
    "    # Ideally this should not be necessary, but it is here just in case.\n",
    "    if row[\"seq\"] is np.nan:\n",
    "        return -1000\n",
    "    \n",
    "    teloLength = getTeloNPBoundary(row[\"seq\"])\n",
    "    return teloLength\n",
    "\n",
    "# The following will multiprocess the rowToTeloBP function\n",
    "for sampleKey in sampleQnames.keys():\n",
    "    sampleDf = sampleQnames[sampleKey]\n",
    "    \n",
    "    pandarallel.initialize(progress_bar=True )\n",
    "    sampleDf[\"teloBPLengths\"] = sampleDf.parallel_apply(rowToTeloBP,axis=1)\n",
    "\n",
    "    # I highly recommend multi-processing, but if you want to single process,\n",
    "    # comment out the above two lines and uncomment the following line:\n",
    "    # sampleDf[\"teloBPLengths\"] = sampleDf.apply(lambda row: rowToTeloBP(row), axis=1)\n",
    "\n",
    "    sampleQnames[sampleKey] = sampleDf\n",
    "\n",
    "    # save the output to a csv file. \n",
    "    # Note that the seq column is removed from the table before saving \n",
    "    sampleQnames[sampleKey] = sampleQnames[sampleKey].drop(columns=[\"seq\"])\n",
    "    sampleQnames[sampleKey].to_csv(f\"{outputDir}/{sampleKey}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the TeloNP results (Much of this code can be reduced into a single cell, separated for clarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the inputted tables have different column names for their \"end.aln\" column, like \"JH39.1ug.NB88uq.end.aln\", so this section will fix this\n",
    "\n",
    "for sampleKey in sampleQnames:\n",
    "    if not (\"end.aln\" in sampleQnames[sampleKey].columns):\n",
    "        # merge any columns containing end.aln\n",
    "        colSearchList = [x for x in sampleQnames[sampleKey].columns if \"end.aln\" in x]\n",
    "        if len(colSearchList) == 0:\n",
    "            print(f\"No end.aln column found in {sampleKey}\")\n",
    "            continue\n",
    "        # merge\n",
    "        sampleQnames[sampleKey][\"end.aln\"] = sampleQnames[sampleKey][colSearchList].max(axis=1)\n",
    "        #drop old columns\n",
    "        sampleQnames[sampleKey].drop(columns=colSearchList, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TeloNP will return the length in bp from the end of the sequence to the telomere boundary, meaning it will include any \n",
    "# barcode or telotag sequence as telomere. Here we are adjusting for this. \n",
    "\n",
    "for sampleKey in sampleQnames:\n",
    "    sampleDf = sampleQnames[sampleKey]\n",
    "    sampleDf[\"end.aln + 10\"] = sampleDf[\"end.aln\"] + 10\n",
    "    sampleDf[\"TeloNPCorrectedLength\"] = sampleDf[\"teloBPLengths\"] - sampleDf[\"end.aln + 10\"]\n",
    "    # if unnamed column exists, drop it\n",
    "    if \"Unnamed: 0\" in sampleDf.columns:\n",
    "        sampleDf.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing any rows with teloBPLengths < 0\n",
    "for sampleKey in sampleQnames.keys():\n",
    "    sampleDf = sampleQnames[sampleKey]\n",
    "    sampleDf = sampleDf[sampleDf[\"TeloNPCorrectedLength\"] > 0]\n",
    "    sampleQnames[sampleKey] = sampleDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed files\n",
    "\n",
    "outputDir = \"output/TeloNPOutput\"\n",
    "\n",
    "for sampleKey in sampleQnames.keys():\n",
    "    sampleQnames[sampleKey].to_csv(f\"{outputDir}/{sampleKey}.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
